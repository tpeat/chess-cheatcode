{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "deccb363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tristanpeat/miniforge3/envs/tensorflow/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# internal\n",
    "\n",
    "from util.conversions import onehot_from_fen, fen_from_filename, fen_from_64\n",
    "from util.models import CNN_BatchNormLessFiltersLastLayer, CNN_BatchNormLessFilters, CNN_NoDropout, CNN_Dropout, CNN_Dropout_BatchNorm, CNN_BatchNorm, FullyConnected, LogisticRegression, CNN_LessFilters, CNN_BatchNormLessFilters\n",
    "from util.models import save_model\n",
    "from util.samplers import make_samplers\n",
    "\n",
    "# external \n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import numpy as np;\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time, datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# maybe outdated, can't find it\n",
    "# from torchsummary import summary\n",
    "\n",
    "from random import randint\n",
    "\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from random import shuffle\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import torch.optim as optim\n",
    "\n",
    "device =torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# needs to be small because \n",
    "BATCH_SIZE = 10\n",
    "\n",
    "# create dataset as list of images\n",
    "DATASET_PATH = '/Users/tristanpeat/Documents/cs/chess-cheatcode/Secondus/data/chess-dataset/labeled_preprocessed'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d6bbf5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded with: 500 images\n"
     ]
    }
   ],
   "source": [
    "# generate dataset\n",
    "def generate_dataset(path):\n",
    "    out = []\n",
    "    for img in os.listdir(path):\n",
    "        img_label = re.sub(r'[\\_][0-9]+', '',img) # remove underscores for dups\n",
    "        try:\n",
    "            label = onehot_from_fen(fen_from_filename(img_label))\n",
    "        except:\n",
    "            print(img)\n",
    "            print(\"ERROR\")\n",
    "            continue\n",
    "        # cv2 method of converting an image to a tensor\n",
    "        # img_as_img = cv2.imread(path + \"/\" + img)\n",
    "        # # getting eeror expected np.ndarray (got Nonetype)\n",
    "        # if img_as_img.any() == None:\n",
    "        #     continue\n",
    "        # open as PIL img\n",
    "        img = Image.open(path + '/' + img)\n",
    "        transform = transforms.Compose([transforms.PILToTensor()])\n",
    "        out.append((transform(img), label))\n",
    "    return out\n",
    "\n",
    "dataset = generate_dataset(DATASET_PATH)\n",
    "print(\"Dataset loaded with:\", len(dataset), \"images\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea94898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get samplers and loaders\n",
    "train_sampler, val_sampler, test_sampler = make_samplers(dataset,\n",
    "                                          validation_split=0.06,\n",
    "                                          test_split=.1,\n",
    "                                          shuffle_dataset = True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           sampler=train_sampler)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           sampler=val_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=dataset,\n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          sampler=test_sampler)  \n",
    "\n",
    "print(f'Train loader contains {len(train_loader)} batches of size {BATCH_SIZE}')\n",
    "print(f'Val loader contains {len(val_loader)} batches of size {BATCH_SIZE}')\n",
    "print(f'Test loader contains {len(test_loader)} batches of size {BATCH_SIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434c4566",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set baseline accuracy\n",
    "def calculateNaiveAcc(transform=None,\n",
    "                      root='train_full'):\n",
    "\n",
    "        pathlist = list(Path(root).glob('**/*.*'))\n",
    "        n_files = len(pathlist)\n",
    "        _data = glob.glob(f\"{root}/*.*\")\n",
    "        dataset_size = len(os.listdir(root))\n",
    "        labels = []\n",
    "\n",
    "        for idx in range(dataset_size):\n",
    "            img = _data[:dataset_size][idx]\n",
    "            img_label = re.sub(r'[\\_][0-9]+', '',img) # remove underscores for dups\n",
    "            try:\n",
    "                label = onehot_from_fen(fen_from_filename(img_label))\n",
    "                labels.append(label)\n",
    "            except:\n",
    "                print(img)\n",
    "                raise\n",
    "        flat = np.array(labels[:][:][:]).astype(int).flatten()\n",
    "        \n",
    "        counts = np.bincount(flat)\n",
    "        most_common = np.argmax(counts)\n",
    "        naive_acc = np.mean( flat == most_common )\n",
    "        print (f'Total Number of labeled Spaces: {np.shape(flat)[0]}\\n'\n",
    "               f'Most Common Element: {most_common} '\n",
    "               f'\\nAccuracy of Guessing that Every Time: {naive_acc}')\n",
    "        return naive_acc\n",
    "\n",
    "naive_acc = calculateNaiveAcc(root='data/chess-dataset/labeled_preprocessed') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113a8f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "def train_model(model: nn.Module, \n",
    "                log_dir: str,\n",
    "                train_loader: torch.utils.data.DataLoader,\n",
    "                criterion: torch.nn.modules.Module,\n",
    "                optimizer: torch.optim.Optimizer,\n",
    "                num_epochs: int=1,\n",
    "                log_freq: int=5,\n",
    "                print_guess=False,\n",
    "                print_guess_freq=50,\n",
    "                test_model_after_each_epoch=False,\n",
    "                val_loader: torch.utils.data.DataLoader=None,\n",
    "                test_loader: torch.utils.data.DataLoader=None,\n",
    "                suppress_output: bool=True,\n",
    "                disable_tqdm: bool=False,\n",
    "            ) -> Tuple[nn.Module, str]:\n",
    "    ''' A messy training loop with lots of extraneous logging functionality '''\n",
    "    \n",
    "    # Create Logging Directory for Tensorboard\n",
    "    # now = time.mktime(datetime.datetime.now().timetuple()) - 1550000000\n",
    "    # log_dir = f'{log_dir} ({now})/'\n",
    "    # logger = Logger(log_dir)\n",
    "    # print(f'Training model. Logging to: \"{log_dir}\"\\n')\n",
    "\n",
    "    model = model.to(device) # Send model to GPU if possible\n",
    "    model.train() # Set model to training mode\n",
    "    \n",
    "    # for drawing predictions to images\n",
    "    # renderer = DrawChessPosition(delimiter='-')\n",
    "    \n",
    "    def validate_model(model, overall_step, loader=None, val=False):\n",
    "        accu = test_model(model, loader, criterion, \n",
    "                                       print_guess=False, \n",
    "                                       disable_tqdm=disable_tqdm)\n",
    "        if not val: return accu\n",
    "        else:\n",
    "            info = { 'validation_accuracy': accu }\n",
    "            # for key, value in info.items():\n",
    "            #     logger.scalar_summary(key, value, overall_step)\n",
    "        return accu\n",
    "\n",
    "    total_step = len(train_loader)\n",
    "    validate_model(model, overall_step=0, loader=val_loader, val=True)\n",
    "    for epoch in range(num_epochs):\n",
    "        if print_guess: print(f'Epoch {epoch+1}')\n",
    "        running_loss = 0\n",
    "        \n",
    "        \n",
    "        # Tqdm will create a progress bar\n",
    "        with tqdm(total=len(train_loader), \n",
    "                  desc=f'Epoch {epoch+1}', \n",
    "                  unit=' minibatches',\n",
    "                  disable=(print_guess or disable_tqdm)) as pbar:\n",
    "            \n",
    "            # Iterate through minibatches\n",
    "            for step, (images, labels) in enumerate(train_loader):\n",
    "                # print(\"thing\", thing)\n",
    "                images, labels = images.to(device), labels.long().to(device)\n",
    "\n",
    "                output = model(images).to(device)\n",
    "                _,class_labels = torch.max(labels,2) \n",
    "                _, argmax = torch.max(output, 2)\n",
    "\n",
    "                accuracy = float((class_labels == \n",
    "                                  argmax.squeeze()).float().mean().cpu())\n",
    "\n",
    "                loss = criterion(output.reshape(10*64,13).float(),\n",
    "                                 class_labels.reshape(10*64))\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += float(loss.item())\n",
    "\n",
    "                pbar.set_postfix(training_accuracy=accuracy, loss=loss.item(), refresh=True)\n",
    "                pbar.update(1)\n",
    "\n",
    "                if step % log_freq == 0:\n",
    "                    overall_step = epoch*total_step + step\n",
    "                    \n",
    "                    info = { 'loss': loss.item(), 'accuracy': accuracy }\n",
    "\n",
    "                    # for key, value in info.items():\n",
    "                    #     logger.scalar_summary(key, value, overall_step)\n",
    "                    \n",
    "\n",
    "                    #               [original_imgs[0].cpu()]}\n",
    "\n",
    "                    # for tag, images in info.items():\n",
    "                    #     logger.image_summary(tag, images, overall_step)\n",
    "\n",
    "                    # for key, value in model.named_parameters():\n",
    "                    #     key = key.replace('.', '/')\n",
    "                    #     logger.histo_summary(key, \n",
    "                    #                          value.data.cpu().numpy(), \n",
    "                    #                          overall_step)\n",
    "                    #     try:\n",
    "                    #         logger.histo_summary(key+'/grad', \n",
    "                    #                              value.grad.data.cpu().numpy(),\n",
    "                    #                              overall_step)\n",
    "                    #     except (AttributeError):\n",
    "                    #         # During transfer learning some of the variables \n",
    "                    #         # don't have grads\n",
    "                    #         pass\n",
    "\n",
    "                if print_guess and step % print_guess_freq == 0:\n",
    "                    overall_step = epoch*total_step + step\n",
    "                    print(f\"\\n{60*'-'}\\nBatch Number: {overall_step}\")\n",
    "                    print(f\"Example training point:\")\n",
    "                    print(f\"Actual: {fen_from_64(class_labels.cpu()[0])}\")\n",
    "                    print(f\"Guess: {fen_from_64(argmax.cpu()[0])}\")\n",
    "                    print(f\"Example Accuracy: {float((class_labels[0] == argmax[0]).float().mean().cpu())}\")\n",
    "\n",
    "                    # board_actual = renderer.draw(fen_from_64(class_labels.cpu()[0]))\n",
    "                    # board_guess = renderer.draw(fen_from_64(argmax.cpu()[0]))\n",
    "                    # renderer.show_side_by_side(board1= original_imgs[0],\n",
    "                    #                            board2=board_guess, \n",
    "                    #                            board1_title='Actual (Preprocessed)',\n",
    "                    #                            board2_title='Prediction (Re'\n",
    "                    #                                         'ndered to image)')\n",
    "        \n",
    "        if not suppress_output:   \n",
    "            print(f\"{epoch}: Training loss: {running_loss/len(train_loader)}\")\n",
    "            print(f\"{epoch}: Training accuracy: {accuracy}\")\n",
    "        \n",
    "        if test_model_after_each_epoch:\n",
    "            validate_model(model, overall_step=overall_step, loader=val_loader, val=True)\n",
    "        \n",
    "\n",
    "    final_val_acc = validate_model(model, overall_step=overall_step, loader=val_loader, val=True)\n",
    "    final_train_acc = validate_model(model, overall_step=overall_step, loader=train_loader)\n",
    "    final_test_acc = validate_model(model, overall_step=overall_step, loader=test_loader)\n",
    "    return (model, log_dir, final_train_acc, final_val_acc, final_test_acc)\n",
    "\n",
    "def test_model(model: nn.Module, \n",
    "                test_loader: torch.utils.data.DataLoader,\n",
    "                criterion: torch.nn.modules.Module,\n",
    "                print_guess: bool=False,\n",
    "                print_guess_freq: int=50,\n",
    "                suppress_output: bool=True,\n",
    "                disable_tqdm: bool=False,) -> float:\n",
    "    \n",
    "    model = model.to(device)\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    total_step = len(test_loader)\n",
    "        \n",
    "    # for drawing predictions to images\n",
    "    # renderer = DrawChessPosition(delimiter='-')\n",
    "    with torch.no_grad():\n",
    "        # Tqdm will create a progress bar\n",
    "        with tqdm(total=len(test_loader), \n",
    "                desc=f'Test Batches', \n",
    "                unit=' minibatches',\n",
    "                disable=(print_guess or disable_tqdm)) as pbar:\n",
    "\n",
    "            # Iterate through minibatches\n",
    "            for step, (images, labels) in enumerate(test_loader):\n",
    "                # images is a torch tensor, labels is the string description\n",
    "                images, labels = images.to(device), labels.long().to(device)\n",
    "\n",
    "                output = model(images).to(device)\n",
    "                _,class_labels = torch.max(labels,2) \n",
    "                _, argmax = torch.max(output, 2)\n",
    "\n",
    "                accuracy = float((class_labels == \n",
    "                                argmax.squeeze()).float().mean().cpu())\n",
    "\n",
    "                loss = criterion(output.reshape(10*64,13).float(),\n",
    "                                class_labels.reshape(10*64))\n",
    "                losses.append(float(loss.item()))\n",
    "                accuracies.append(accuracy)\n",
    "\n",
    "                pbar.set_postfix(test_acc=accuracy, test_loss=loss.item(), refresh=True)\n",
    "                pbar.update(1)\n",
    "\n",
    "                if print_guess and step % print_guess_freq == 0:\n",
    "\n",
    "                    overall_step = total_step + step\n",
    "                    print(f\"\\n{60*'-'}\\nTest Batch Number: {overall_step}\")\n",
    "                    print(f\"Example testing point:\")\n",
    "                    print(f\"Actual: {fen_from_64(class_labels.cpu()[0])}\")\n",
    "                    print(f\"Guess: {fen_from_64(argmax.cpu()[0])}\")\n",
    "                    print(f\"Example Accuracy: {float((class_labels[0] == argmax[0]).float().mean().cpu())}\")\n",
    "\n",
    "                    # board_actual = renderer.draw(fen_from_64(class_labels.cpu()[0]))\n",
    "                    # board_guess = renderer.draw(fen_from_64(argmax.cpu()[0]))\n",
    "                    # renderer.show_side_by_side(board1= original_imgs[0],\n",
    "                    #                         board2=board_guess, \n",
    "                    #                         board1_title='Actual',\n",
    "                    #                         board2_title='Prediction (Re'\n",
    "                    #                                         'ndered to image)')\n",
    "\n",
    "    if not suppress_output:                   \n",
    "        print(f'\\nAvg. Accuracy of the network on test images: {np.average(accuracies)}')\n",
    "        print(f'Avg. Loss of the network on test images: {np.average(losses)}')\n",
    "\n",
    "    return np.average(accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0fa0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main loop\n",
    "\n",
    "np.warnings.filterwarnings('ignore') # they were getting annoying...\n",
    "\n",
    "num_epochs = 25\n",
    "log_freq=2\n",
    "log_dirs = []\n",
    "cnns = [CNN_BatchNormLessFiltersLastLayer, CNN_BatchNormLessFilters, CNN_NoDropout, \n",
    "        CNN_Dropout, CNN_Dropout_BatchNorm, CNN_BatchNorm]\n",
    "basic_models = [FullyConnected, LogisticRegression]\n",
    "all_models = cnns + basic_models\n",
    "new_models = [CNN_LessFilters, CNN_BatchNormLessFilters]\n",
    "\n",
    "for learning_rate in [.0005]:\n",
    "    for model_type in new_models:\n",
    "        net = model_type(batch_size=BATCH_SIZE)\n",
    "        print(f'Training: {net.name}\\nLearning Rate: {learning_rate}')\n",
    "\n",
    "        if net.name == 'LogisticRegression (L2 regularization)':\n",
    "            weight_decay=.05 # add L2 regularizer for logreg\n",
    "        else: weight_decay=0\n",
    "        optimizer = optim.Adam(net.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "        log_dir = f'./logs/{net.name}_lr{learning_rate}'\n",
    "        criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "        # print a summary of the net statistics\n",
    "        #         summary(net.to(device), (BATCH_SIZE*32, 3, 25, 25))\n",
    "\n",
    "        #     images, labels, original_imgs = next(iter(train_loader))\n",
    "        #     y = net.to(device)(Variable(images.to(device)))\n",
    "        #     make_dot(y)\n",
    "\n",
    "        # Run the model\n",
    "        start_time = time.time()\n",
    "\n",
    "\n",
    "        model, log_dir, final_train_acc, final_val_acc, final_test_acc = train_model(net,\n",
    "                                                    log_dir,\n",
    "                                                    train_loader,\n",
    "                                                    criterion,\n",
    "                                                    optimizer,\n",
    "                                                    num_epochs, \n",
    "                                                    log_freq,\n",
    "                                                    print_guess_freq=100,\n",
    "                                                    print_guess=False,\n",
    "                                                    test_model_after_each_epoch=True,\n",
    "                                                    val_loader=val_loader,\n",
    "                                                    test_loader=test_loader,\n",
    "                                                    disable_tqdm=True) # or print_guess=False for tqdm\n",
    "        log_dirs.append(log_dir)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        print(f'Final Train Accuracy: {final_train_acc:.8f}')\n",
    "        print(f'Final Test Accuracy: {final_test_acc:.8f}')\n",
    "        print(f'Final Validation Accuracy: {final_val_acc:.8f}')\n",
    "        print(f'Elapsed Time: {elapsed_time/60:.2f} minutes')\n",
    "        save_model(model, f'model_{model.name}_{learning_rate}.pt')\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
